{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importation des bibliothèques nécessaires\nfrom keras.preprocessing.image import img_to_array  # Convertir une image en tableau NumPy\nfrom sklearn.utils import shuffle  # Mélanger les données\nfrom sklearn.preprocessing import LabelBinarizer  # Convertir les étiquettes en format binaire\nfrom sklearn.model_selection import train_test_split  # Diviser les données en ensembles d'entraînement et de test\nfrom keras.preprocessing.image import ImageDataGenerator  # Génération d'images augmentées\nfrom sklearn.metrics import classification_report, confusion_matrix  # Évaluation des performances du modèle\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img  # Traitement d'images avec Keras\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T09:10:16.355359Z","iopub.execute_input":"2024-01-13T09:10:16.355905Z","iopub.status.idle":"2024-01-13T09:10:16.364104Z","shell.execute_reply.started":"2024-01-13T09:10:16.355870Z","shell.execute_reply":"2024-01-13T09:10:16.362783Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/agriculture-crop-images/kag2'","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:25:38.129817Z","iopub.execute_input":"2024-01-13T07:25:38.131607Z","iopub.status.idle":"2024-01-13T07:25:38.136899Z","shell.execute_reply.started":"2024-01-13T07:25:38.131552Z","shell.execute_reply":"2024-01-13T07:25:38.135899Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Data Augmentation Configuration and Training Data Generator Initialization**\n","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1.0/255.0, horizontal_flip=True,vertical_flip=True, rotation_range=90)\n \ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(224,224),\n        batch_size=64,\n        class_mode='categorical',\n        shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:25:47.654914Z","iopub.execute_input":"2024-01-13T07:25:47.655359Z","iopub.status.idle":"2024-01-13T07:25:47.733483Z","shell.execute_reply.started":"2024-01-13T07:25:47.655328Z","shell.execute_reply":"2024-01-13T07:25:47.732589Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 804 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_generator.class_indices\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:25:56.844335Z","iopub.execute_input":"2024-01-13T07:25:56.844765Z","iopub.status.idle":"2024-01-13T07:25:56.854958Z","shell.execute_reply.started":"2024-01-13T07:25:56.844732Z","shell.execute_reply":"2024-01-13T07:25:56.853590Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'jute': 0, 'maize': 1, 'rice': 2, 'sugarcane': 3, 'wheat': 4}"},"metadata":{}}]},{"cell_type":"markdown","source":"**Model Training VGG16**\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:26:07.474846Z","iopub.execute_input":"2024-01-13T07:26:07.475429Z","iopub.status.idle":"2024-01-13T07:26:07.621510Z","shell.execute_reply.started":"2024-01-13T07:26:07.475386Z","shell.execute_reply":"2024-01-13T07:26:07.620414Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Initialization of VGG16 Pre-trained Model and Freezing Layers**\n","metadata":{}},{"cell_type":"code","source":"pre_model = VGG16(weights = 'imagenet', \n                 include_top = False, \n                 input_shape = (224, 224, 3))\n\nfor layer in pre_model.layers:\n    layer.trainable = False              ","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:26:19.329264Z","iopub.execute_input":"2024-01-13T07:26:19.330528Z","iopub.status.idle":"2024-01-13T07:26:20.560398Z","shell.execute_reply.started":"2024-01-13T07:26:19.330490Z","shell.execute_reply":"2024-01-13T07:26:20.559215Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pre_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:26:28.803542Z","iopub.execute_input":"2024-01-13T07:26:28.803935Z","iopub.status.idle":"2024-01-13T07:26:28.862420Z","shell.execute_reply.started":"2024-01-13T07:26:28.803906Z","shell.execute_reply":"2024-01-13T07:26:28.860907Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n=================================================================\nTotal params: 14714688 (56.13 MB)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 14714688 (56.13 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Adding Flatten and Final Dense Layer to VGG16 Pre-trained Model**","metadata":{}},{"cell_type":"code","source":"last_layer = Flatten()(pre_model.output)\nfinal_layer = Dense(5, activation='softmax')(last_layer)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:26:40.875483Z","iopub.execute_input":"2024-01-13T07:26:40.876112Z","iopub.status.idle":"2024-01-13T07:26:40.910542Z","shell.execute_reply.started":"2024-01-13T07:26:40.876071Z","shell.execute_reply":"2024-01-13T07:26:40.909336Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=pre_model.input, outputs=final_layer)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:26:50.295084Z","iopub.execute_input":"2024-01-13T07:26:50.295468Z","iopub.status.idle":"2024-01-13T07:26:50.306621Z","shell.execute_reply.started":"2024-01-13T07:26:50.295439Z","shell.execute_reply":"2024-01-13T07:26:50.305071Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:26:57.359655Z","iopub.execute_input":"2024-01-13T07:26:57.360357Z","iopub.status.idle":"2024-01-13T07:26:57.430048Z","shell.execute_reply.started":"2024-01-13T07:26:57.360316Z","shell.execute_reply":"2024-01-13T07:26:57.428758Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 5)                 125445    \n                                                                 \n=================================================================\nTotal params: 14840133 (56.61 MB)\nTrainable params: 125445 (490.02 KB)\nNon-trainable params: 14714688 (56.13 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Compiling the Model**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:27:09.360517Z","iopub.execute_input":"2024-01-13T07:27:09.361122Z","iopub.status.idle":"2024-01-13T07:27:09.600958Z","shell.execute_reply.started":"2024-01-13T07:27:09.361070Z","shell.execute_reply":"2024-01-13T07:27:09.599884Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:27:16.940128Z","iopub.execute_input":"2024-01-13T07:27:16.940596Z","iopub.status.idle":"2024-01-13T07:27:17.011394Z","shell.execute_reply.started":"2024-01-13T07:27:16.940560Z","shell.execute_reply":"2024-01-13T07:27:17.005635Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 5)                 125445    \n                                                                 \n=================================================================\nTotal params: 14840133 (56.61 MB)\nTrainable params: 125445 (490.02 KB)\nNon-trainable params: 14714688 (56.13 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit_generator(train_generator, epochs=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:27:34.135362Z","iopub.execute_input":"2024-01-13T07:27:34.135948Z","iopub.status.idle":"2024-01-13T08:09:28.038739Z","shell.execute_reply.started":"2024-01-13T07:27:34.135889Z","shell.execute_reply":"2024-01-13T08:09:28.037109Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_41/2975305634.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(train_generator, epochs=10)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n13/13 [==============================] - 230s 17s/step - loss: 1.8794 - accuracy: 0.3396\nEpoch 2/10\n13/13 [==============================] - 228s 17s/step - loss: 1.1595 - accuracy: 0.5274\nEpoch 3/10\n13/13 [==============================] - 226s 17s/step - loss: 0.8594 - accuracy: 0.6741\nEpoch 4/10\n13/13 [==============================] - 225s 17s/step - loss: 0.6860 - accuracy: 0.7624\nEpoch 5/10\n13/13 [==============================] - 225s 17s/step - loss: 0.6046 - accuracy: 0.7998\nEpoch 6/10\n13/13 [==============================] - 225s 17s/step - loss: 0.5328 - accuracy: 0.8271\nEpoch 7/10\n13/13 [==============================] - 225s 17s/step - loss: 0.4641 - accuracy: 0.8644\nEpoch 8/10\n13/13 [==============================] - 225s 17s/step - loss: 0.4214 - accuracy: 0.8781\nEpoch 9/10\n13/13 [==============================] - 225s 17s/step - loss: 0.4055 - accuracy: 0.8856\nEpoch 10/10\n13/13 [==============================] - 225s 17s/step - loss: 0.3720 - accuracy: 0.8881\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7e1e2e0aaa10>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Save Model**\n","metadata":{}},{"cell_type":"code","source":"model.save('my_model.keras')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:11:29.671426Z","iopub.execute_input":"2024-01-13T08:11:29.671986Z","iopub.status.idle":"2024-01-13T08:11:29.990290Z","shell.execute_reply.started":"2024-01-13T08:11:29.671946Z","shell.execute_reply":"2024-01-13T08:11:29.988934Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:11:55.235385Z","iopub.execute_input":"2024-01-13T08:11:55.235784Z","iopub.status.idle":"2024-01-13T08:11:55.241863Z","shell.execute_reply.started":"2024-01-13T08:11:55.235754Z","shell.execute_reply":"2024-01-13T08:11:55.240516Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Evaluating the model**","metadata":{}},{"cell_type":"code","source":"model.evaluate_generator(test_generator)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T09:16:33.300238Z","iopub.execute_input":"2024-01-13T09:16:33.300798Z","iopub.status.idle":"2024-01-13T09:17:55.481387Z","shell.execute_reply.started":"2024-01-13T09:16:33.300762Z","shell.execute_reply":"2024-01-13T09:17:55.479925Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_41/2205837447.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  model.evaluate_generator(test_generator)\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[0.4751569330692291, 0.8457711338996887]"},"metadata":{}}]},{"cell_type":"code","source":"#TestData\ntest_data_dir = '/kaggle/input/agriculture-crop-images/crop_images'\ntest_datagen = ImageDataGenerator(rescale=1./255)\n \ntest_batchsize = 64\n \ntest_generator = test_datagen.flow_from_directory(\n        test_data_dir,\n        target_size=(224,225),\n        batch_size=64,\n        class_mode='categorical',\n        shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:12:11.901118Z","iopub.execute_input":"2024-01-13T08:12:11.901712Z","iopub.status.idle":"2024-01-13T08:12:11.937823Z","shell.execute_reply.started":"2024-01-13T08:12:11.901676Z","shell.execute_reply":"2024-01-13T08:12:11.936507Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Found 201 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nmodel.load_weights(\"my_model.keras\")\nclass_labels = test_generator.class_indices\nclass_labels = {v: k for k, v in class_labels.items()}\nclasses = list(class_labels.values())\nY_pred = model.predict_generator(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:12:49.345417Z","iopub.execute_input":"2024-01-13T08:12:49.345938Z","iopub.status.idle":"2024-01-13T08:14:13.078458Z","shell.execute_reply.started":"2024-01-13T08:12:49.345892Z","shell.execute_reply":"2024-01-13T08:14:13.076962Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_41/119025590.py:6: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n  Y_pred = model.predict_generator(test_generator)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate_generator(test_generator)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:39:22.984488Z","iopub.execute_input":"2024-01-13T08:39:22.984967Z","iopub.status.idle":"2024-01-13T08:40:45.521759Z","shell.execute_reply.started":"2024-01-13T08:39:22.984934Z","shell.execute_reply":"2024-01-13T08:40:45.520348Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_41/2205837447.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  model.evaluate_generator(test_generator)\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[0.4751569330692291, 0.8457711338996887]"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:15:14.590159Z","iopub.execute_input":"2024-01-13T08:15:14.590643Z","iopub.status.idle":"2024-01-13T08:15:14.849539Z","shell.execute_reply.started":"2024-01-13T08:15:14.590609Z","shell.execute_reply":"2024-01-13T08:15:14.848600Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Some predictions**\n","metadata":{}},{"cell_type":"code","source":"def predict_crop(path,actual,class_labels):\n    predict_datagen = ImageDataGenerator(rescale=1./255)\n    img = cv2.imread(path)\n    img = cv2.resize(img, (224, 224))\n    img = np.array(img).reshape((1, 224, 224, 3))\n    Y_pred = model.predict(img)\n    y_pred = np.argmax(Y_pred, axis=1)\n    if y_pred == actual:\n        print('Correct prediction')\n    else:\n        print(\"Wrong Prediction!!\")\n    print('Actual class \"{0}\" and predicted class \"{1}\"'.format(class_labels[int(y_pred)],class_labels[actual]))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:15:31.380129Z","iopub.execute_input":"2024-01-13T08:15:31.380550Z","iopub.status.idle":"2024-01-13T08:15:31.389465Z","shell.execute_reply.started":"2024-01-13T08:15:31.380517Z","shell.execute_reply":"2024-01-13T08:15:31.388086Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"predict_crop('/kaggle/input/agriculture-crop-images/test_crop_image/jute-field.jpg',0,class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:15:52.860134Z","iopub.execute_input":"2024-01-13T08:15:52.860572Z","iopub.status.idle":"2024-01-13T08:15:53.437571Z","shell.execute_reply.started":"2024-01-13T08:15:52.860541Z","shell.execute_reply":"2024-01-13T08:15:53.436584Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 454ms/step\nCorrect prediction\nActual class \"jute\" and predicted class \"jute\"\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_crop('/kaggle/input/agriculture-crop-images/test_crop_image/maize_fieldmexico.jpeg',1,class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:16:06.815514Z","iopub.execute_input":"2024-01-13T08:16:06.816079Z","iopub.status.idle":"2024-01-13T08:16:07.231557Z","shell.execute_reply.started":"2024-01-13T08:16:06.816029Z","shell.execute_reply":"2024-01-13T08:16:07.230294Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 347ms/step\nCorrect prediction\nActual class \"maize\" and predicted class \"maize\"\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_crop('/kaggle/input/agriculture-crop-images/test_crop_image/rice-field.jpg',0,class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:16:19.465354Z","iopub.execute_input":"2024-01-13T08:16:19.465789Z","iopub.status.idle":"2024-01-13T08:16:19.836612Z","shell.execute_reply.started":"2024-01-13T08:16:19.465757Z","shell.execute_reply":"2024-01-13T08:16:19.835391Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 298ms/step\nCorrect prediction\nActual class \"jute\" and predicted class \"jute\"\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_crop('/kaggle/input/agriculture-crop-images/test_crop_image/sugarcane fields.jpg',1,class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T08:16:30.089791Z","iopub.execute_input":"2024-01-13T08:16:30.090237Z","iopub.status.idle":"2024-01-13T08:16:30.449722Z","shell.execute_reply.started":"2024-01-13T08:16:30.090205Z","shell.execute_reply":"2024-01-13T08:16:30.448843Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 295ms/step\nCorrect prediction\nActual class \"maize\" and predicted class \"maize\"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}